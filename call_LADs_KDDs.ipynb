{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50c53da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ctspecific_HMMs.py\n",
    "\n",
    "from pomegranate import *\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "from pybedtools import BedTool\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8cfd1d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths for LADs\n",
    "bedgraphs_dir = 'files/LB1_bedgraphs'\n",
    "outdir = 'out_dir'\n",
    "\n",
    "## paths for KDDs\n",
    "#bedgraphs_dir = 'bedgraphs_h3k9me2'\n",
    "#outdir = 'KDDs_out'\n",
    "#out_beds = 'KDD_BEDs\n",
    "\n",
    "# organization df (org_df) is a file describing the samples\n",
    "# required columns are cell_type, replicate, chip\n",
    "# be a tsv/csv etc if you change this command\n",
    "org_df = pd.read_table('files/sample_info.tsv', sep='\\t')\n",
    "\n",
    "# states dict for LADs\n",
    "states_dict = {\n",
    "        2:['nonLAD','LAD'],\n",
    "        3:['nonLAD','T2-LAD','T1-LAD'],\n",
    "        4:['nonLAD','T3-LAD','T2-LAD','T1-LAD'],\n",
    "        5:['nonLAD','T4-LAD','T3-LAD','T2-LAD','T1-LAD']\n",
    "    }\n",
    "    \n",
    "# # states dict for KDDs\n",
    "# states_dict = {\n",
    "#         2:['nonKDD','KDD'],\n",
    "#         3:['nonKDD','T2-KDD','T1-KDD'],\n",
    "#         4:['nonKDD','T3-KDD','T2-KDD','T1-KDD'],\n",
    "#         5:['nonKDD','T4-KDD','T3-KDD','T2-KDD','T1-KDD']\n",
    "#     }\n",
    "\n",
    "encode_blocklist = BedTool('files/encode_blocklist.bed')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "64d9655e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_bedgraph(f, binsize, blocklistbed):\n",
    "    \"\"\"\n",
    "    parses bedgraph file for use in the HMM training\n",
    "    f: path to bedGraph file\n",
    "    binsize: resolution of bedgraph file (we used 20kb)\n",
    "    blocklistbed: BED file of regions to remove, e.g. ENCODE blocklist\n",
    "    \"\"\"\n",
    "    \n",
    "    # filter non-canonical chromosomes, this will have to be changed\n",
    "    # if this is applied to nonhuman samples\n",
    "    canonical_chroms = [ 'chr' + str(x) for x in range(1,23) ] + ['chrY', 'chrX']\n",
    "    \n",
    "    # load bedGraph file and convert to BED format\n",
    "    indf_pre = pd.read_csv(f, sep='\\t', low_memory=False, header=None, \n",
    "        names=['chrom','start','stop','score']).dropna().query('chrom in @canonical_chroms')\n",
    "    indf_pre['id'] = indf_pre.index\n",
    "    \n",
    "    inbed = BedTool.from_dataframe(indf_pre[['chrom','start','stop','id','score']]).sort()\n",
    "    inbed_filt = inbed.subtract(blocklistbed).sort()\n",
    "    \n",
    "    indf = inbed_filt.to_dataframe()\n",
    "    indf.columns = ['chrom','start','stop','id','score']\n",
    "    indf = indf[['chrom','start','stop','score']].copy()\n",
    "\n",
    "    indf['size'] = indf['stop'] - indf['start']\n",
    "\n",
    "    # for some reason deepTools sometimes produces bins > specified resolution\n",
    "    # and that messes up the HMM, so this fixes that\n",
    "    indf_split = indf.query('size > @binsize').copy() \n",
    "    \n",
    "    if len(indf_split) > 0: \n",
    "        to_add = []\n",
    "        for ix, row in indf_split.iterrows():\n",
    "            n_intervals = row['size'] / binsize\n",
    "            start = row['start']\n",
    "            chrom = row['chrom']\n",
    "            score = row[f'score']\n",
    "            for val in range(int(n_intervals)):\n",
    "                to_add.append(pd.DataFrame({\n",
    "                    'chrom':[row['chrom']],\n",
    "                    'start':[start],\n",
    "                    'stop':[start + binsize],\n",
    "                    'score':[score]\n",
    "                }))\n",
    "                start = start + binsize\n",
    "\n",
    "        indf = pd.concat([indf.query('size == @binsize')[['chrom','start','stop',f'score']],\n",
    "                          pd.concat(to_add)]).query('chrom in @canonical_chroms')\n",
    "    else:\n",
    "        indf = indf.query('size == @binsize')[['chrom','start','stop',f'score']].query('chrom in @canonical_chroms')\n",
    "    return(indf)\n",
    "\n",
    "def assign_categories(dat, cat_names):\n",
    "    \"\"\"\n",
    "    Assign categories to specific HMM states\n",
    "    based on the mean ChIP-seq coverage\n",
    "    in bins assigned to that state.\n",
    "    \n",
    "    dat is the binned data with HMM predicted states\n",
    "    generated by lad_utils.hmm_predict()\n",
    "    \n",
    "    cat_names should be provided based on which should be\n",
    "    assigned to sequecing coverage level in ascending order.\n",
    "    \"\"\"\n",
    "    n_states = len(dat['hmm_pred'].unique())\n",
    "    n_cats = len(cat_names)\n",
    "    if n_states != n_cats:\n",
    "        print(f'{n_states} in data, but {n_cats} provided. '\\\n",
    "              f'Number of categories must match the number '\\\n",
    "              f'of HMM states.')\n",
    "    else:\n",
    "        \n",
    "        cols = ['score0','score1'] # each cell type has 2 replicates\n",
    "        # cols = ['score']\n",
    "        \n",
    "        states = []\n",
    "        means = []\n",
    "        \n",
    "        for state in dat['hmm_pred'].unique():\n",
    "            states.append(state)\n",
    "            means.append(np.mean(dat.query(f'hmm_pred == {state}')[cols].mean()))\n",
    "           \n",
    "        # sort means and associated states, ascending\n",
    "        sorted_means = sorted(means)\n",
    "        means_to_states = dict(zip(means, states))\n",
    "        \n",
    "        sorted_states = []\n",
    "        \n",
    "        for val in sorted_means:\n",
    "            sorted_states.append(means_to_states[val])\n",
    "    \n",
    "        names_to_states = dict(zip(sorted_states, cat_names))\n",
    "        dat['category'] = dat['hmm_pred'].replace(names_to_states)\n",
    "        return dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "86b3f8c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Improvement: 39739.78349005245\tTime (s): 0.1082\n",
      "[2] Improvement: 14580.812490047363\tTime (s): 0.1088\n",
      "[3] Improvement: 6803.650687383357\tTime (s): 0.1079\n",
      "[4] Improvement: 3338.9679254316143\tTime (s): 0.1066\n",
      "[5] Improvement: 1710.150860462687\tTime (s): 0.1067\n",
      "[6] Improvement: 872.4883866441378\tTime (s): 0.1078\n",
      "[7] Improvement: 432.81914242589846\tTime (s): 0.09831\n",
      "[8] Improvement: 207.77879664201464\tTime (s): 0.09843\n",
      "[9] Improvement: 96.88976005959557\tTime (s): 0.09935\n",
      "[10] Improvement: 44.20016316269175\tTime (s): 0.09824\n",
      "[11] Improvement: 19.875595168676227\tTime (s): 0.09812\n",
      "[12] Improvement: 8.868650123258703\tTime (s): 0.09817\n",
      "[13] Improvement: 3.948258370903204\tTime (s): 0.09919\n",
      "[14] Improvement: 1.7614704561274266\tTime (s): 0.0981\n",
      "[15] Improvement: 0.7903598838311154\tTime (s): 0.09822\n",
      "[16] Improvement: 0.3577188085473608\tTime (s): 0.09942\n",
      "[17] Improvement: 0.16371454785985406\tTime (s): 0.09945\n",
      "[18] Improvement: 0.07591114859678783\tTime (s): 0.09813\n",
      "[19] Improvement: 0.035712294149561785\tTime (s): 0.09816\n",
      "[20] Improvement: 0.01706141918839421\tTime (s): 0.09924\n",
      "[21] Improvement: 0.008278838940896094\tTime (s): 0.09902\n",
      "[22] Improvement: 0.004079777339939028\tTime (s): 0.09823\n",
      "[23] Improvement: 0.002039850252913311\tTime (s): 0.09936\n",
      "[24] Improvement: 0.00103395213955082\tTime (s): 0.09791\n",
      "[25] Improvement: 0.0005302946956362575\tTime (s): 0.09814\n",
      "[26] Improvement: 0.00027479437994770706\tTime (s): 0.09808\n",
      "[27] Improvement: 0.00014385583926923573\tTime (s): 0.09939\n",
      "[28] Improvement: 7.534818723797798e-05\tTime (s): 0.09947\n",
      "[29] Improvement: 4.032865399494767e-05\tTime (s): 0.09903\n",
      "[30] Improvement: 2.1345418645069003e-05\tTime (s): 0.09933\n",
      "[31] Improvement: 1.1193362297490239e-05\tTime (s): 0.09796\n",
      "[32] Improvement: 6.3382904045283794e-06\tTime (s): 0.09808\n",
      "[33] Improvement: 3.6435085348784924e-06\tTime (s): 0.09829\n",
      "[34] Improvement: 1.330510713160038e-06\tTime (s): 0.09993\n",
      "[35] Improvement: 1.03181810118258e-06\tTime (s): 0.09883\n",
      "[36] Improvement: 7.046182872727513e-07\tTime (s): 0.09822\n",
      "[37] Improvement: 7.558264769613743e-08\tTime (s): 0.09943\n",
      "[38] Improvement: 2.7281930670142174e-07\tTime (s): 0.09821\n",
      "[39] Improvement: 2.3572647478431463e-07\tTime (s): 0.09807\n",
      "[40] Improvement: -7.690687198191881e-08\tTime (s): 0.09841\n",
      "Total Training Improvement: 67863.45269766812\n",
      "Total Training Time (s): 4.2445\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-78ea09d43d08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cell_type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mdat_rep1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_bedgraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{bedgraphs_dir}/{ct}_rep1.sorted.bedgraph'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_blocklist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mdat_rep2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_bedgraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{bedgraphs_dir}/{ct}_rep2.sorted.bedgraph'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_blocklist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHiddenMarkovModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mdat_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNormalDistribution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdat_rep1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdat_rep2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgorithm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'baum-welch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-e605bb9b85a3>\u001b[0m in \u001b[0;36mparse_bedgraph\u001b[0;34m(f, binsize, blocklistbed)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mindf_pre\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindf_pre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0minbed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBedTool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindf_pre\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'chrom'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'start'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'stop'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0minbed_filt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minbed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubtract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblocklistbed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/LAD_analysis/lib/python3.7/site-packages/pybedtools/bedtool.py\u001b[0m in \u001b[0;36mfrom_dataframe\u001b[0;34m(self, df, outfile, sep, header, na_rep, index, **kwargs)\u001b[0m\n\u001b[1;32m    551\u001b[0m                               index=index)\n\u001b[1;32m    552\u001b[0m         \u001b[0mdefault_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m         \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mdefault_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/LAD_analysis/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[1;32m   3226\u001b[0m             \u001b[0mdecimal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3227\u001b[0m         )\n\u001b[0;32m-> 3228\u001b[0;31m         \u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3230\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/LAD_analysis/lib/python3.7/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    200\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnicodeWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mwriter_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/LAD_analysis/lib/python3.7/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_save_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/LAD_analysis/lib/python3.7/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36m_save_chunk\u001b[0;34m(self, start_i, end_i)\u001b[0m\n\u001b[1;32m    338\u001b[0m                 \u001b[0mdecimal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m                 \u001b[0mdate_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m                 \u001b[0mquoting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquoting\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m             )\n\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/LAD_analysis/lib/python3.7/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mto_native_types\u001b[0;34m(self, slicer, na_rep, quoting, **kwargs)\u001b[0m\n\u001b[1;32m    757\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_object\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mquoting\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"object\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# change ChIP depending on whether you're calling LADs or KDDs\n",
    "for ix, row in org_df.query('chip == \"LB1\"').iterrows():\n",
    "    \n",
    "    # predict LADs/KDDs for 2-5 states to compare\n",
    "    for n_states in [2, 3, 4, 5]:\n",
    "        \n",
    "        # train one HMM model per cell type\n",
    "        ct = row['cell_type']\n",
    "        dat_rep1 = parse_bedgraph(f'{bedgraphs_dir}/{ct}_rep1.sorted.bedgraph',20000, encode_blocklist)\n",
    "        dat_rep2 = parse_bedgraph(f'{bedgraphs_dir}/{ct}_rep2.sorted.bedgraph',20000, encode_blocklist)\n",
    "        model = HiddenMarkovModel()\n",
    "        dat_model = model.from_samples(NormalDistribution, n_components=n_states, X=[dat_rep1['score'].tolist(),dat_rep2['score'].tolist()], algorithm='baum-welch', verbose=True, n_jobs=20)\n",
    "        dat = dat_rep1.merge(dat_rep2, on=['chrom','start','stop'], suffixes=('_rep1', '_rep2'))\n",
    "        dat['hmm_pred'] = dat_model.predict(dat[['score_rep1','score_rep2']].to_numpy(),\n",
    "                                        algorithm='viterbi')[1:]\n",
    "        trained_model_json = dat_model.to_json()\n",
    "        if not os.path.exists(f'{outdir}/hmms_{n_states}states'):\n",
    "            os.makedirs(f'{outdir}/hmms_{n_states}states')\n",
    "            os.makedirs(f'{outdir}/hmm_calls_{n_states}states')\n",
    "            os.makedirs(f'{outdir}/BED_files_{n_states}states')\n",
    "            \n",
    "        # save the trained model\n",
    "        with open(f'{outdir}/hmms_{n_states}states/{ct}.json', 'w') as outfile:\n",
    "            json.dump(trained_model_json, outfile)\n",
    "            \n",
    "        # save calls per bin\n",
    "        dat.to_csv(f'{outdir}/hmm_calls_{n_states}states/{ct}.tsv',\n",
    "              sep='\\t', index=False)\n",
    "        \n",
    "        # assign LAD/KDD categories per bin, and save BED file\n",
    "        dat = pd.read_table(f'{outdir}/hmm_calls_{n_states}states/{ct}.tsv', names=['chrom','start','stop','score0','score1','hmm_pred'],\n",
    "                           header=0)\n",
    "        dat_w_cats = assign_categories(dat, states_dict[n_states])\n",
    "        for cat in dat_w_cats['category'].unique():\n",
    "            bed = BedTool.from_dataframe(dat_w_cats.query('category == @cat')).sort().merge(d=1)\n",
    "            bed.to_dataframe().to_csv(f'{outdir}/BED_files_{n_states}states/{ct}_{cat}s.bed',\n",
    "                             sep='\\t', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9642093",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
