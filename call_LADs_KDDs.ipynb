{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1c241e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pomegranate import *\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "from pybedtools import BedTool\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3cada845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths for LADs\n",
    "bedgraphs_dir = 'files/LB1_bedgraphs'\n",
    "outdir = 'out_dir'\n",
    "\n",
    "## paths for KDDs\n",
    "#bedgraphs_dir = 'bedgraphs_h3k9me2'\n",
    "#outdir = 'KDDs_out'\n",
    "#out_beds = 'KDD_BEDs\n",
    "\n",
    "# organization df (org_df) is a file describing the samples\n",
    "# required columns are cell_type, replicate, chip\n",
    "# be a tsv/csv etc if you change this command\n",
    "org_df = pd.read_table('files/sample_info.tsv', sep='\\t')\n",
    "\n",
    "# states dict for LADs\n",
    "states_dict = {\n",
    "        2:['nonLAD','LAD'],\n",
    "        3:['nonLAD','T2-LAD','T1-LAD'],\n",
    "        4:['nonLAD','T3-LAD','T2-LAD','T1-LAD'],\n",
    "        5:['nonLAD','T4-LAD','T3-LAD','T2-LAD','T1-LAD']\n",
    "    }\n",
    "    \n",
    "# # states dict for KDDs\n",
    "# states_dict = {\n",
    "#         2:['nonKDD','KDD'],\n",
    "#         3:['nonKDD','T2-KDD','T1-KDD'],\n",
    "#         4:['nonKDD','T3-KDD','T2-KDD','T1-KDD'],\n",
    "#         5:['nonKDD','T4-KDD','T3-KDD','T2-KDD','T1-KDD']\n",
    "#     }\n",
    "\n",
    "encode_blocklist = BedTool('files/encode_blocklist.bed')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5bba0ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_bedgraph(f, binsize, blocklistbed):\n",
    "    \"\"\"\n",
    "    parses bedgraph file for use in the HMM training\n",
    "    f: path to bedGraph file\n",
    "    binsize: resolution of bedgraph file (we used 20kb)\n",
    "    blocklistbed: BED file of regions to remove, e.g. ENCODE blocklist\n",
    "    \"\"\"\n",
    "    \n",
    "    # filter non-canonical chromosomes, this will have to be changed\n",
    "    # if this is applied to nonhuman samples\n",
    "    canonical_chroms = [ 'chr' + str(x) for x in range(1,23) ] + ['chrY', 'chrX']\n",
    "    \n",
    "    # load bedGraph file and convert to BED format\n",
    "    indf_pre = pd.read_csv(f, sep='\\t', low_memory=False, header=None, \n",
    "        names=['chrom','start','stop','score']).dropna().query('chrom in @canonical_chroms')\n",
    "    indf_pre['id'] = indf_pre.index\n",
    "    \n",
    "    inbed = BedTool.from_dataframe(indf_pre[['chrom','start','stop','id','score']]).sort()\n",
    "    inbed_filt = inbed.subtract(blocklistbed).sort()\n",
    "    \n",
    "    indf = inbed_filt.to_dataframe()\n",
    "    indf.columns = ['chrom','start','stop','id','score']\n",
    "    indf = indf[['chrom','start','stop','score']].copy()\n",
    "\n",
    "    indf['size'] = indf['stop'] - indf['start']\n",
    "\n",
    "    # for some reason deepTools sometimes produces bins > specified resolution\n",
    "    # and that messes up the HMM, so this fixes that\n",
    "    indf_split = indf.query('size > @binsize').copy() \n",
    "    \n",
    "    if len(indf_split) > 0: \n",
    "        to_add = []\n",
    "        for ix, row in indf_split.iterrows():\n",
    "            n_intervals = row['size'] / binsize\n",
    "            start = row['start']\n",
    "            chrom = row['chrom']\n",
    "            score = row[f'score']\n",
    "            for val in range(int(n_intervals)):\n",
    "                to_add.append(pd.DataFrame({\n",
    "                    'chrom':[row['chrom']],\n",
    "                    'start':[start],\n",
    "                    'stop':[start + binsize],\n",
    "                    'score':[score]\n",
    "                }))\n",
    "                start = start + binsize\n",
    "\n",
    "        indf = pd.concat([indf.query('size == @binsize')[['chrom','start','stop',f'score']],\n",
    "                          pd.concat(to_add)]).query('chrom in @canonical_chroms')\n",
    "    else:\n",
    "        indf = indf.query('size == @binsize')[['chrom','start','stop',f'score']].query('chrom in @canonical_chroms')\n",
    "    return(indf)\n",
    "\n",
    "def assign_categories(dat, cat_names):\n",
    "    \"\"\"\n",
    "    Assign categories to specific HMM states\n",
    "    based on the mean ChIP-seq coverage\n",
    "    in bins assigned to that state.\n",
    "    \n",
    "    \n",
    "    cat_names should be provided based on which should be\n",
    "    assigned to sequecing coverage level in ascending order.\n",
    "    \"\"\"\n",
    "    n_states = len(dat['hmm_pred'].unique())\n",
    "    n_cats = len(cat_names)\n",
    "    if n_states != n_cats:\n",
    "        print(f'{n_states} in data, but {n_cats} provided. '\\\n",
    "              f'Number of categories must match the number '\\\n",
    "              f'of HMM states.')\n",
    "    else:\n",
    "        \n",
    "        cols = ['score0','score1'] # each cell type has 2 replicates\n",
    "        # cols = ['score']\n",
    "        \n",
    "        states = []\n",
    "        means = []\n",
    "        \n",
    "        for state in dat['hmm_pred'].unique():\n",
    "            states.append(state)\n",
    "            means.append(np.mean(dat.query(f'hmm_pred == {state}')[cols].mean()))\n",
    "           \n",
    "        # sort means and associated states, ascending\n",
    "        sorted_means = sorted(means)\n",
    "        means_to_states = dict(zip(means, states))\n",
    "        \n",
    "        sorted_states = []\n",
    "        \n",
    "        for val in sorted_means:\n",
    "            sorted_states.append(means_to_states[val])\n",
    "    \n",
    "        names_to_states = dict(zip(sorted_states, cat_names))\n",
    "        dat['category'] = dat['hmm_pred'].replace(names_to_states)\n",
    "        return dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a9e3ad55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change ChIP depending on whether you're calling LADs or KDDs\n",
    "for ix, row in org_df.query('chip == \"LB1\"').iterrows():\n",
    "    \n",
    "    # predict LADs/KDDs for 2-5 states to compare\n",
    "    for n_states in [2, 3, 4, 5]:\n",
    "        \n",
    "        # train one HMM model per cell type\n",
    "        ct = row['cell_type']\n",
    "        dat_rep1 = parse_bedgraph(f'{bedgraphs_dir}/{ct}_rep1.sorted.bedgraph',20000, encode_blocklist)\n",
    "        dat_rep2 = parse_bedgraph(f'{bedgraphs_dir}/{ct}_rep2.sorted.bedgraph',20000, encode_blocklist)\n",
    "        model = HiddenMarkovModel()\n",
    "        dat_model = model.from_samples(NormalDistribution, n_components=n_states, X=[dat_rep1['score'].tolist(),dat_rep2['score'].tolist()], algorithm='baum-welch', verbose=True, n_jobs=20)\n",
    "        dat = dat_rep1.merge(dat_rep2, on=['chrom','start','stop'], suffixes=('_rep1', '_rep2'))\n",
    "        dat['hmm_pred'] = dat_model.predict(dat[['score_rep1','score_rep2']].to_numpy(),\n",
    "                                        algorithm='viterbi')[1:]\n",
    "        trained_model_json = dat_model.to_json()\n",
    "        if not os.path.exists(f'{outdir}/hmms_{n_states}states'):\n",
    "            os.makedirs(f'{outdir}/hmms_{n_states}states')\n",
    "            os.makedirs(f'{outdir}/hmm_calls_{n_states}states')\n",
    "            os.makedirs(f'{outdir}/BED_files_{n_states}states')\n",
    "            \n",
    "        # save the trained model\n",
    "        with open(f'{outdir}/hmms_{n_states}states/{ct}.json', 'w') as outfile:\n",
    "            json.dump(trained_model_json, outfile)\n",
    "            \n",
    "        # save calls per bin\n",
    "        dat.to_csv(f'{outdir}/hmm_calls_{n_states}states/{ct}.tsv',\n",
    "              sep='\\t', index=False)\n",
    "        \n",
    "        # assign LAD/KDD categories per bin, and save BED file\n",
    "        dat = pd.read_table(f'{outdir}/hmm_calls_{n_states}states/{ct}.tsv', names=['chrom','start','stop','score0','score1','hmm_pred'],\n",
    "                           header=0)\n",
    "        dat_w_cats = assign_categories(dat, states_dict[n_states])\n",
    "        for cat in dat_w_cats['category'].unique():\n",
    "            bed = BedTool.from_dataframe(dat_w_cats.query('category == @cat')).sort().merge(d=1)\n",
    "            bed.to_dataframe().to_csv(f'{outdir}/BED_files_{n_states}states/{ct}_{cat}s.bed',\n",
    "                             sep='\\t', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb26e665",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
